Agent Prompting Guide

AI-Powered Job Application Framework for Data Professionals

Overview
This framework leverages Cursor's AI capabilities to streamline and automate the job application process for data professionals. The system uses multiple specialized agents to handle different aspects of job hunting, from company research to interview preparation.
1. Cursor Composer Template

Purpose
Creates an integrated job application management system using Cursor's AI-powered features for real-time code generation and multi-file editing capabilities.
Agent Structure

Primary Agents:
1. Application Manager
• Orchestrates the entire application process
• Tracks application status and deadlines
• Maintains communication history
• Generates status reports and next actions
2. Job Research Analyzer
• Scrapes job boards (LinkedIn, Indeed, Glassdoor)
• Analyzes job descriptions for key requirements
• Identifies company tech stack and data infrastructure
• Generates company culture insights
• Calculates job-skill match percentage
3. Resume Optimizer
• Customizes resume based on job description
• Highlights relevant data projects and skills
• Generates ATS-friendly formatting
• Creates role-specific achievements bullets
• Maintains versions for different job types
4. Portfolio Builder
• Curates relevant data projects
• Generates project descriptions
• Creates interactive data visualizations
• Maintains GitHub repository documentation
• Builds case study presentations
5. Interview Preparation Agent
• Creates company-specific preparation guides
• Generates practice technical questions
• Prepares SQL/Python coding challenges
• Creates mock interview scenarios
• Maintains a knowledge base of common data interview questions
Required API Documentation

APIs:
- LinkedIn API: Job search and company information
- GitHub API: Portfolio management
- HuggingFace API: Text analysis and generation
- OpenAI API: Content generation and customization
- Kaggle API: Dataset access and project ideas
- Glassdoor API: Company reviews and salary data
- ATS Simulation API: Resume scanning simulation

2. Cursor Rules File (.cursorrules)

Framework Rules

# Agent Communication Protocol
agent_communication:
  message_format: JSON
  required_fields: ["agent_id", "action_type", "priority", "timestamp"]
  max_response_time: 5s

# Code Generation Standards
code_standards:
  language_preferences:
    - python: ["pandas", "numpy", "sklearn"]
    - sql: ["PostgreSQL", "BigQuery"]
    - visualization: ["plotly", "seaborn"]
  documentation_required: true
  test_coverage_minimum: 80%

# Data Processing Guidelines
data_handling:
  personal_info_encryption: required
  resume_versions: track_all
  application_status_logging: enabled

3. Requirements.txt

# Core Dependencies
python-linkedin-v2==0.8.3
python-github==1.55
openai==1.3.0
pandas==2.0.0
numpy==1.23.5
plotly==5.13.0
beautifulsoup4==4.11.2
pdfminer.six==20221105
python-docx==0.8.11
streamlit==1.22.0

# Database
sqlalchemy==1.4.46
psycopg2-binary==2.9.5

# Testing
pytest==7.3.1
pytest-cov==4.0.0

# Security
python-dotenv==0.21.1
cryptography==39.0.0

4. Environment Variables (.env)

# API Keys
LINKEDIN_CLIENT_ID="your_linkedin_client_id"
LINKEDIN_CLIENT_SECRET="your_linkedin_secret"
GITHUB_TOKEN="your_github_token"
OPENAI_API_KEY="your_openai_key"
GLASSDOOR_API_KEY="your_glassdoor_key"

# Database Configuration
DB_HOST="your_db_host"
DB_NAME="applications_db"
DB_USER="your_db_user"
DB_PASSWORD="your_db_password"

# Application Settings
MAX_CONCURRENT_APPLICATIONS=5
RESUME_STORAGE_PATH="/path/to/resumes"
PORTFOLIO_PATH="/path/to/portfolio"

5. Product Requirement Document (PRD)

Core Features

Application Tracking System
• Real-time application status dashboard
• Automated follow-up reminders
• Application success metrics
• Integration with email for communication tracking
Resume Management
• Version control for different job types
• ATS optimization scoring
• Skill-keyword matching
• Achievement quantification
Portfolio Development
• Project recommendation engine
• Automated documentation generation
• Interactive visualization creation
• GitHub activity optimization
Interview Preparation
• Company-specific question bank
• Technical assessment simulator
• Behavioral question preparation
• Feedback analysis and improvement suggestions
Data Models

# Application Status Model
class ApplicationStatus:
    company: str
    position: str
    application_date: datetime
    status: Enum["Applied", "Screening", "Technical", "Onsite", "Offer", "Rejected"]
    next_action: str
    priority: int
    notes: List[str]

# Resume Version Model
class ResumeVersion:
    job_type: str
    skills_highlighted: List[str]
    achievements: List[str]
    version_date: datetime
    ats_score: float
    
# Interview Preparation Model
class InterviewPrep:
    company: str
    tech_stack: List[str]
    practice_questions: List[str]
    company_culture: dict
    salary_range: tuple

Success Metrics
• Application response rate
• Interview conversion rate
• Resume ATS pass rate
• Portfolio engagement metrics
• Time-to-offer optimization
Usage Instructions
1. Initialize the framework:

from application_framework import ApplicationManager

manager = ApplicationManager()


2. Start a new application:

job_details = {
    "company": "DataCorp Inc",
    "position": "Senior Data Scientist",
    "job_description": "job_description.txt",
    "application_deadline": "2024-12-01"
}

application = manager.start_application(job_details)


3. Generate customized assets:

# Customize resume
resume = application.optimize_resume()

# Update portfolio
portfolio = application.curate_portfolio()

# Prepare for interview
prep_materials = application.generate_interview_prep()


This framework provides a comprehensive solution for managing the entire job application process for data professionals, leveraging AI to optimize each step and increase success rates.